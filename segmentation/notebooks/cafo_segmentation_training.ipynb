{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook notes: probably the most important notebook. Takes the model weights from transfer learning and then trains on the 2000+ CAFO images with Microsoft segmentation. Then saves model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import date\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "from ground_truth_dataset import groundTruthDataset\n",
    "from data_functions import splitDataset, returnLoaders\n",
    "from metrics import returnPreReF\n",
    "sys.path.insert(0, '../models')\n",
    "from unet_model import UNet\n",
    "sys.path.insert(0, '../train')\n",
    "from training import train_one_epoch, valid_one_epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2 # For ground truth data, there's 2 classes of Background, CAFO\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = groundTruthDataset(\"../../../../../datadrive/data/raw/ground_truth/\", \n",
    "                             transform=True, \n",
    "                             make_small=True, \n",
    "                             ignore_lagoon=True)\n",
    "#dataset = groundTruthDataset(\"../../../segmentation_ground_truth\", make_small=True)\n",
    "datasets = splitDataset(dataset)\n",
    "trainloader, validloader, testloader = returnLoaders(datasets, batch_size, True)\n",
    "model = UNet(3, NUM_CLASSES) # 3 Channels, 2 Classes (background, CAFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained = UNet(3, 2)\n",
    "model_pretrained.load_state_dict(torch.load('../../../saved_models/driven/07_24_driven_lr_0.0003_epochs_40_batch_size_4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transferring over the weights in new model\n",
    "model_dict = model.state_dict()\n",
    "pretrained_model_dict = model_pretrained.state_dict()\n",
    "for key in pretrained_model_dict:\n",
    "    if (key != 'outc.conv.weight') & (key != 'outc.conv.bias'):\n",
    "        model_dict[key] = pretrained_model_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_batches = len(trainloader)\n",
    "valid_num_batches = len(validloader)\n",
    "train_num_examples = len(trainloader.dataset)\n",
    "valid_num_examples = len(validloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model to either cpu or gpu\n",
    "model.to(device)            \n",
    "\n",
    "#Define loss function\n",
    "#Weight due to class imbalance\n",
    "pos_weight = torch.tensor([1, 30]) #23 is good when doing 3 class\n",
    "pos_weight = torch.reshape(pos_weight,(1,2,1,1)).to(device)\n",
    "criterion = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3,\n",
    "                                     weight_decay = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "date_prefix = today.strftime(\"%m_%d\")\n",
    "log_dir_suffix = f\"{date_prefix}_groundtruth_lr_{3e-4}_epochs_{10}_batch_size_{4}\"\n",
    "log_dir = \"../logs/groundtruth/\" + log_dir_suffix\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss 0.3962 - acc 0.9837 - Mean IoU 0.1090: 100%|██████████| 193/193 [01:35<00:00,  2.01it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss 0.2152 - acc 0.9914 - Mean IoU 0.2014 - Precision 0.2737 - Recall 0.4327: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "Epoch 1 - loss 0.1976 - acc 0.9928 - Mean IoU 0.2179:   1%|          | 1/193 [00:00<00:32,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss 0.1558 - acc 0.9914 - Mean IoU 0.1888: 100%|██████████| 193/193 [01:35<00:00,  2.01it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss 0.1658 - acc 0.9946 - Mean IoU 0.2052 - Precision 0.4335 - Recall 0.2805: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "Epoch 2 - loss 0.0962 - acc 0.9940 - Mean IoU 0.2157:   1%|          | 1/193 [00:00<00:31,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss 0.1056 - acc 0.9928 - Mean IoU 0.2096: 100%|██████████| 193/193 [01:36<00:00,  2.00it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss 0.1023 - acc 0.9909 - Mean IoU 0.2039 - Precision 0.2655 - Recall 0.4677: 100%|██████████| 42/42 [00:30<00:00,  1.37it/s]\n",
      "Epoch 3 - loss 0.0795 - acc 0.9918 - Mean IoU 0.2682:   1%|          | 1/193 [00:00<00:30,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss 0.0859 - acc 0.9924 - Mean IoU 0.2113: 100%|██████████| 193/193 [01:36<00:00,  2.01it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss 0.1099 - acc 0.9947 - Mean IoU 0.1876 - Precision 0.4488 - Recall 0.2437: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "Epoch 4 - loss 0.0608 - acc 0.9944 - Mean IoU 0.2434:   1%|          | 1/193 [00:00<00:31,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - loss 0.0789 - acc 0.9928 - Mean IoU 0.2217: 100%|██████████| 193/193 [01:36<00:00,  2.00it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - loss 0.0753 - acc 0.9926 - Mean IoU 0.2455 - Precision 0.3316 - Recall 0.4859: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "Epoch 5 - loss 0.0495 - acc 0.9923 - Mean IoU 0.1664:   1%|          | 1/193 [00:00<00:33,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - loss 0.0754 - acc 0.9926 - Mean IoU 0.2220: 100%|██████████| 193/193 [01:37<00:00,  1.99it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - loss 0.0731 - acc 0.9899 - Mean IoU 0.2198 - Precision 0.2639 - Recall 0.5679: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "Epoch 6 - loss 0.0474 - acc 0.9943 - Mean IoU 0.2184:   1%|          | 1/193 [00:00<00:32,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - loss 0.0708 - acc 0.9926 - Mean IoU 0.2288: 100%|██████████| 193/193 [01:36<00:00,  1.99it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - loss 0.0806 - acc 0.9948 - Mean IoU 0.2488 - Precision 0.4720 - Recall 0.3448: 100%|██████████| 42/42 [00:30<00:00,  1.39it/s]\n",
      "Epoch 7 - loss 0.0596 - acc 0.9933 - Mean IoU 0.2840:   1%|          | 1/193 [00:00<00:32,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training in Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - loss 0.0697 - acc 0.9928 - Mean IoU 0.2305: 100%|██████████| 193/193 [01:36<00:00,  2.00it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Validation in Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - loss 0.0686 - acc 0.9921 - Mean IoU 0.2471 - Precision 0.3191 - Recall 0.5225: 100%|██████████| 42/42 [00:30<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "model.zero_grad()\n",
    "class_list = [0, 1]\n",
    "for epoch in range(8):\n",
    "    ### TRAINING ###\n",
    "    print(\"Beginning Training in Epoch \" + str(epoch))\n",
    "    with tqdm(total = train_num_batches) as epoch_pbar:\n",
    "        model.train()\n",
    "        train_loss, train_correct, \\\n",
    "            train_IoU = train_one_epoch(epoch, train_num_batches, model, \n",
    "                                        device, trainloader, epoch_pbar, \n",
    "                                        optimizer, writer, criterion)\n",
    "\n",
    "    ### VALIDATION ###\n",
    "    print(\"Beginning Validation in Epoch \" + str(epoch))\n",
    "    valid_loss = []\n",
    "    valid_correct = 0\n",
    "\n",
    "    conf_matrix = np.zeros((2, 2))\n",
    "\n",
    "    with tqdm(total = valid_num_batches) as epoch_pbar:\n",
    "        model.eval()                           \n",
    "        valid_loss, valid_correct, \\\n",
    "            conf_matrix, valid_IoU = valid_one_epoch(epoch, valid_num_batches, model, \n",
    "                                                     device, validloader, epoch_pbar, \n",
    "                                                     optimizer, writer, criterion,\n",
    "                                                     conf_matrix, class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returnPreReF(conf_matrix, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing it out on validation\n",
    "val_example = next(iter(trainloader))\n",
    "inputs = val_example[0].to(device)\n",
    "labels = val_example[1].to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "_, predictions = torch.max(outputs, 1)\n",
    "predictions_one_hot = torch.nn.functional.one_hot(predictions).permute(0, 3, 1, 2)\n",
    "y_pred = predictions.flatten().cpu().numpy()\n",
    "_, blah = torch.max(labels, 1)\n",
    "y_true = blah.flatten().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((predictions[0] == 1).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import compute_unary, unary_from_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCRFmask(img_tensor, prediction, num_classes):\n",
    "    \"\"\"\n",
    "    img_tensor : Tensor (Channel x Width x Length)\n",
    "        Tensor of the original image that is gpu attached\n",
    "    prediction : Tensor (Width x Length)\n",
    "        Softmax output of the model\n",
    "    num_classes : Int\n",
    "        Number of prediction classes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A post-processed prediction mask for the image tensor\n",
    "    \n",
    "    \"\"\"        \n",
    "    # Changes input image into 255 format\n",
    "    changedInput = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype('uint8') \n",
    "    \n",
    "    # Get unary energy of the prediction image\n",
    "    feat_first = prediction.reshape((num_classes, - 1)).cpu().numpy()\n",
    "    unary = unary_from_softmax(feat_first)\n",
    "    unary = np.ascontiguousarray(unary)        \n",
    "    d = dcrf.DenseCRF2D(img_tensor.shape[2], img_tensor.shape[1], num_classes) # Create CRF filter\n",
    "    d.setUnaryEnergy(unary)\n",
    "    \n",
    "    # Add original image to CRF\n",
    "    d.addPairwiseGaussian(sxy=(3, 3), compat=5, kernel=dcrf.DIAG_KERNEL,\n",
    "                          normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    d.addPairwiseBilateral(sxy=(3, 3), srgb=(3, 3, 3), rgbim=np.ascontiguousarray(changedInput),\n",
    "                       compat=10,\n",
    "                       kernel=dcrf.DIAG_KERNEL,\n",
    "                       normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    \n",
    "    Q = d.inference(5)\n",
    "    res = np.argmax(Q, axis=0).reshape((img_tensor.shape[1], img_tensor.shape[2])) # Get the new mask    \n",
    "    res = torch.nn.functional.one_hot(torch.Tensor(res).to(torch.int64)).permute(2, 0, 1) # Make it one hot\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New plotting function including CRF\n",
    "kwarg_dict = { 'BACKGROUND':{'cmap':'prism', 'alpha': 0.5},\n",
    "                  'Lagoon': {'cmap':'cool', 'alpha': 0.5},\n",
    "                  'CAFO Shed': {'cmap':'hot', 'alpha': 0.0}}\n",
    "\n",
    "def plotLabelPredictCRF(inputs, label, predictions_one_hot, softmax, \n",
    "                        num_classes, kwarg_dict):\n",
    "    \"\"\"\n",
    "    inputs : Tensor (Channel x Width x Length)\n",
    "        Tensor of a CAFO image\n",
    "    label : Tensor (Num Classes x Width x Length)\n",
    "        Tensor of the labels for original CAFO image\n",
    "    predictions_one_hot : Tensor (Num Classes x Width x Length)\n",
    "        One-hot tensor of predictions from model\n",
    "    softmax : Tensor (Width x Length)\n",
    "        Softmax output of the model\n",
    "    num_classes : Int\n",
    "        Number of classes\n",
    "    kwarg_dict : Dict\n",
    "        Dictionary for plotting\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Plots the original image, prediction mask, and crf mask\n",
    "    \"\"\"\n",
    "    crf_mask = returnCRFmask(inputs, softmax, num_classes)\n",
    "    changedInput = (inputs.permute(1, 2, 0).cpu().numpy() * 255).astype('uint8') \n",
    "    \n",
    "    f = plt.figure()\n",
    "    a= f.add_subplot(1, 3, 1)    \n",
    "    plt.imshow(changedInput)\n",
    "    if label != None:\n",
    "        plt.imshow(label[0].cpu().numpy(), **kwarg_dict['BACKGROUND'])\n",
    "        plt.imshow(label[1].cpu().numpy(), **kwarg_dict['CAFO Shed']) \n",
    "    plt.axis('off')\n",
    "\n",
    "    a = f.add_subplot(1, 3, 2)\n",
    "    plt.imshow(changedInput)\n",
    "    plt.imshow(predictions_one_hot[0].cpu().numpy(), **kwarg_dict['BACKGROUND'])\n",
    "    plt.imshow(predictions_one_hot[1].cpu().numpy(), **kwarg_dict['CAFO Shed'])    \n",
    "    plt.axis('off')\n",
    "\n",
    "    a = f.add_subplot(1, 3, 3)\n",
    "    plt.imshow(changedInput)\n",
    "    plt.imshow(crf_mask[0].numpy(), **kwarg_dict['BACKGROUND'])\n",
    "    plt.imshow(crf_mask[1].numpy(), **kwarg_dict['CAFO Shed'])    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plotLabelPredictCRF(inputs[i], labels[i], predictions_one_hot[i], outputs[i], NUM_CLASSES, kwarg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now trying on Planet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torchvision.transforms import ToTensor\n",
    "planet_images_dir = '../../../../../datadrive/data/raw/planet_images_il-2019-07/'\n",
    "#pic_list = ['planet_loc_103-date_2019-07-01.tif', 'planet_loc_107-date_2019-07-01.tif', 'planet_loc_110-date_2019-07-01.tif',\n",
    "#           'planet_loc_112-date_2019-07-01.tif']\n",
    "#image_list = [planet_images_dir + i for i in pic_list]\n",
    "image_list = glob.glob(planet_images_dir + '*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planet_images(picture, model, device, kwarg_dict, num_classes):\n",
    "    \n",
    "    with rasterio.open(picture) as src:\n",
    "        b, g, r, n = src.read()\n",
    "    rgb = np.stack((r,g,b), axis=0)   \n",
    "    example = Image.fromarray((np.rollaxis(rgb/rgb.max(), 0, 3)*255).astype(np.uint8))    \n",
    "    example = ToTensor()(example)\n",
    "    with torch.no_grad():\n",
    "        output = model((example.unsqueeze(0)).to(device))    \n",
    "    _, predictions = torch.max(output, 1)\n",
    "    predictions_one_hot = torch.nn.functional.one_hot(predictions, num_classes=num_classes).permute(0, 3, 1, 2).squeeze(0)\n",
    "        \n",
    "    plotLabelPredictCRF(torch.Tensor(rgb/rgb.max()), None, predictions_one_hot, \n",
    "                         output, num_classes, kwarg_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    planet_images(image_list[i], model, device, kwarg_dict, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_2019 = '../../../../../datadrive/data/raw/planet_images_il-2019-07/'\n",
    "dir_2020 = '../../../../../datadrive/data/raw/planet_images_il-2020-07/'\n",
    "image_num_list = ['035', '045', '048', '081', '160', '175', '177', '227']\n",
    "\n",
    "f = plt.figure(figsize=(8,17)) \n",
    "f.suptitle(\"2019 vs 2020 CAFO Prediction on Planet Satellite Images\", y = .92, fontsize=14)\n",
    "for i, number in enumerate(image_num_list):\n",
    "    im2019 = dir_2019 + \"planet_loc_\"+number+\"-date_2019-07-01.tif\"\n",
    "    im2020 = dir_2020 + \"planet_loc_\"+number+\"-date_2020-07-01.tif\"\n",
    "    \n",
    "    with rasterio.open(im2019) as src:\n",
    "        b1, g1, r1, n1 = src.read()\n",
    "    rgb1 = np.stack((r1,g1,b1), axis=0)   \n",
    "    im1 = Image.fromarray((np.rollaxis(rgb1/rgb1.max(), 0, 3)*255).astype(np.uint8))    \n",
    "    im1 = ToTensor()(im1)\n",
    "    with torch.no_grad():\n",
    "        output1 = model((im1.unsqueeze(0)).to(device))    \n",
    "    _, predictions1 = torch.max(output1, 1)\n",
    "    predictions_one_hot1 = torch.nn.functional.one_hot(predictions1).permute(0, 3, 1, 2)\n",
    "    crf_mask1 = returnCRFmask(torch.Tensor(rgb1/rgb1.max()), output1, NUM_CLASSES)\n",
    "    \n",
    "    with rasterio.open(im2020) as src:\n",
    "        b2, g2, r2, n2 = src.read()\n",
    "    rgb2 = np.stack((r2,g2,b2), axis=0)   \n",
    "    im2 = Image.fromarray((np.rollaxis(rgb2/rgb2.max(), 0, 3)*255).astype(np.uint8))    \n",
    "    im2 = ToTensor()(im2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output2 = model((im2.unsqueeze(0)).to(device))    \n",
    "    _, predictions2 = torch.max(output2, 1)\n",
    "    predictions_one_hot2 = torch.nn.functional.one_hot(predictions2).permute(0, 3, 1, 2)\n",
    "    crf_mask2 = returnCRFmask(torch.Tensor(rgb2/rgb2.max()), output2, NUM_CLASSES)\n",
    "    \n",
    "    # BEFORE IMAGE\n",
    "    \n",
    "    a1 = f.add_subplot(len(image_num_list), 6, 6*i + 1)\n",
    "    plt.imshow(im1.permute(1, 2, 0).cpu().numpy())    \n",
    "    plt.axis('off')\n",
    "    \n",
    "    a2 = f.add_subplot(len(image_num_list), 6, 6*i + 2)\n",
    "    plt.imshow(im1.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.imshow(predictions_one_hot1[0][0].cpu().numpy(), **kwarg_dict['BACKGROUND'])    \n",
    "    plt.imshow(predictions_one_hot1[0][1].cpu().numpy(), **kwarg_dict['CAFO Shed'])        \n",
    "    a2.set_title(f'#CAFO: {torch.sum(predictions1 == 0).item()}')\n",
    "    plt.axis('off')    \n",
    "        \n",
    "    a3 = f.add_subplot(len(image_num_list), 6, 6*i + 3)    \n",
    "    plt.imshow(im1.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.imshow(crf_mask1[0].numpy(), **kwarg_dict['BACKGROUND'])\n",
    "    plt.imshow(crf_mask1[1].numpy(), **kwarg_dict['CAFO Shed'])    \n",
    "    plt.axis('off')    \n",
    "    \n",
    "    # AFTER IMAGE\n",
    "    \n",
    "    a4 = f.add_subplot(len(image_num_list), 6, 6*i + 4)\n",
    "    plt.imshow(im2.permute(1, 2, 0).cpu().numpy())    \n",
    "    plt.axis('off')    \n",
    "    \n",
    "    a5 = f.add_subplot(len(image_num_list), 6, 6*i + 5)\n",
    "    plt.imshow(im2.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.imshow(predictions_one_hot2[0][0].cpu().numpy(), **kwarg_dict['BACKGROUND'])    \n",
    "    plt.imshow(predictions_one_hot2[0][1].cpu().numpy(), **kwarg_dict['CAFO Shed'])        \n",
    "    a5.set_title(f'#CAFO: {torch.sum(predictions2 == 0).item()}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a6 = f.add_subplot(len(image_num_list), 6, 6*i + 6)    \n",
    "    plt.imshow(im2.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.imshow(crf_mask2[0].numpy(), **kwarg_dict['BACKGROUND'])\n",
    "    plt.imshow(crf_mask2[1].numpy(), **kwarg_dict['CAFO Shed'])    \n",
    "    plt.axis('off')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"../../../saved_models/finished/model8_10_ia_data.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
